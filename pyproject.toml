[build-system]
requires = ["setuptools>=42", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "pyTorchAutoForge"
version = "0.1.0a0"
description='PyTorchAutoForge library is based on raw PyTorch and designed automate DNN development, model tracking and deployment, tightly integrated with MLflow and Optuna. It supports Spiking networks libraries (WIP). Deployment can be performed using ONNx, pyTorch facilities or TensorRT (WIP). The library is designed to be compatible with Jetson Orin Nano Jetpack rev6.1, with bash script to automatically configure virtualenv.'
readme = "README.md"
requires-python = ">=3.10"
license = {text = "MIT"}
authors = [{name = "Pietro Califano (PC)", email = "petercalifano.gs@gmail.com"}]
dependencies = [
    "torch-tb-profiler<=0.4.3",
    "scikit-learn<=1.6.1",
    "scipy<=1.16.1",
    "numpy<=2.2.1",
    "onnx<=1.17.0",
    "onnxscript<=0.1.0.dev20240609",
    "optuna<=4.1.1",
    "mlflow<=2.19.1",
    "kornia<=0.7.4",
    "albumentations<=1.4.25",
    "pytest<=8.3.5",
    "seaborn<=0.13.3",
    "matplotlib<=3.10.0",
    "colorama<=0.4.6",
    "msgpack<=1.1.0",
    "pynvml; platform_machine == 'x86_64'", # Should only install for x86_64 devices
    "torchvision; platform_machine == 'x86_64'" ,
    "norse; platform_machine == 'x86_64'",
    "tonic; platform_machine == 'x86_64'",
    "aestream; platform_machine == 'x86_64'",
    "expelliarmus; platform_machine == 'x86_64'"
]
classifiers=[
    'Programming Language :: Python :: 3.12',
    'Programming Language :: Python :: 3.11',
    'Programming Language :: Python :: 3.10',
    'License :: OSI Approved :: MIT License',
    'Operating System :: POSIX :: Linux',
]

[tool.setuptools.packages.find]
include = ["pyTorchAutoForge", "pyTorchAutoForge.*"]

